![GitHub Repo Banner](https://ghrb.waren.build/banner?header=%21%5Bpython%5D+podScout&subheader=Lean+RunPod+GPU+watcher.+Network-volume+aware.&bg=431586-9231A8&color=FFFFFF&headerfont=Permanent+Marker&subheaderfont=Kinewave&watermarkpos=bottom-right)
<!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build -->

# podScout

Lean RunPod GPU watcher. Network-volume aware.  
No UI. No dashboards. Just signal.

Author: dancesWithNodes  
License: MIT  

---

## ğŸ¯ What This Does

Polls RunPodâ€™s API.  
Checks availability for specific GPU types.  
Optionally restricts to a datacenter.  
Optionally infers that datacenter from a network volume.  
Optionally sends Pushover notifications.  

Thatâ€™s it.

If a GPU becomes available, youâ€™ll know.  
If it doesnâ€™t, youâ€™ll wait. Like the rest of us.

---

## ğŸ§  Design Principles

- Explicit wins.
- Environment variables override fallbacks.
- Fail fast.
- No magic.
- No external config files.
- One flag. `--once`. Thatâ€™s the list.

If something is misconfigured, it errors. Immediately.  
If an API field changes, it retries. Then errors.

Garbage in, garbage out.

---

## âš™ Configuration

Edit variables at the top of `podScout.py`.

Secrets should be provided via environment variables:

```
export RUNPOD_API_KEY=your_key
export PUSHOVER_APP_TOKEN=your_token
export PUSHOVER_USER_KEY=your_user
```

Fallback constants exist for local testing.  
Env vars win.

### Region Routing Logic

Precedence is explicit:

1. `DATACENTER_ID` set â†’ used directly.
2. Else if `NETWORK_VOLUME_ID` set â†’ datacenter inferred from volume.
3. Else â†’ global pool.

If both are set and disagree â†’ hard failure.  
No guessing.

---

## ğŸŒ Market Mode

`MARKET_MODE` supports:

- `secure`
- `community`
- `both`
- `""` (auto)

Auto mode:
- If `NETWORK_VOLUME_ID` exists â†’ defaults to `secure`
- Else â†’ defaults to `both`

Deterministic. No surprises.

---

## ğŸ–¥ GPU Targets

Use `WATCH_GPU_TYPE_IDS`.

Prefer internal `gpuTypeId` values.  
Display names may work. Until they donâ€™t.

Example:

```python
WATCH_GPU_TYPE_IDS = [
    "NVIDIA GeForce RTX 5090",
]
```

If this list is empty â†’ error.  
Because of course.

---

## ğŸ“Š Availability Classification

Availability is derived from:

- `maxUnreservedGpuCount`
- `availableGpuCounts`

Logic:

- 0 â†’ ğŸ”´ Unavailable
- 1 â†’ ğŸŸ  Low
- 2 â†’ ğŸŸ¡ Medium
- â‰¥3 â†’ ğŸŸ¢ High

If the API returns nothing â†’ treated as unavailable.  
No dice.

---

## ğŸ”” Notifications

Optional. Disabled by default.

Two modes:

### State Change Mode (default)

Notify only when availability changes from false â†’ true.  
Cooldown controlled by:

```
STATE_CHANGE_NOTIFY_COOLDOWN_SECONDS
```

### Periodic Mode

Notify repeatedly while available.  
Cooldown controlled by:

```
PUSHOVER_COOLDOWN_SECONDS
```

If cooldown active â†’ suppressed. Calmly.

---

## ğŸ§ª CLI Flags

Supported flags:

```
--once
```

Thatâ€™s it.

Behavior:

- Runs a single check.
- Exit code `0` if any GPU available.
- Exit code `1` if none available.
- Exit code `2` on error.

Any other flag â†’ immediate failure.

No argparse circus. No shorthand flags. No config files.

---

## ğŸ“¦ Installation

Requires Python 3.9+

Dependency:

```
pip install requests
```

Thatâ€™s the only one.

---

## â–¶ Run

Continuous mode:

```
python podScout.py
```

Single check:

```
python podScout.py --once
```

---

## ğŸ’¥ Failure Modes

Common examples:

- Missing `RUNPOD_API_KEY` â†’ error.
- Invalid `DATACENTER_ID` â†’ validation fails.
- Volume cannot resolve datacenter â†’ error.
- Unknown CLI argument â†’ error.

Messages are blunt.  
Youâ€™ll know what broke.

---

## ğŸ¤– AI Assistance

Portions of this project were generated or refined with the assistance of GPT-5.x (Codex).  
Core logic and design decisions are mine. Boilerplate and repetitive scaffolding were delegated.

Human-reviewed. No blind merges.

---

## ğŸ§¾ License

MIT

Do what you want.  
If it works, great.  
If it doesnâ€™t, you have the source.
